{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to generate events from a pre-trained LogNormMix-Net model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import dpp\n",
    "import numpy as np\n",
    "import torch\n",
    "from copy import deepcopy\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 20, 10\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "import matplotlib.pyplot as plt\n",
    "import cProfile\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['enron_email_dataset', 'eu_email_dataset']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpp.data.list_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "dataset_name = 'enron_email_dataset'  # run dpp.data.list_datasets() to see the list of available datasets\n",
    "\n",
    "# Model config\n",
    "## Marks\n",
    "use_src_marks = True              # Use source marks\n",
    "src_mark_embedding_size = 24          # Size of the src mark embedding (used as RNN input)\n",
    "use_dst_marks = True                  # Use destination marks\n",
    "dst_mark_embedding_size = 24          # Size of the dst mark embedding (used as RNN input)\n",
    "shared_mark_embedding = False          # Should the source and destination marks share an embedding layer (note, embedding sizes must be the same, and have the same range)\n",
    "\n",
    "context_size = 64                # Size of the RNN hidden vector\n",
    "num_mix_components = 30           # Number of components for a mixture model\n",
    "rnn_type = \"LSTM\"                  # What RNN to use as an encoder {\"RNN\", \"GRU\", \"LSTM\"}\n",
    "meta_embedding_size = 16\n",
    "num_meta_classes = 3\n",
    "meta_type = 'basic'\n",
    "\n",
    "# Training config\n",
    "batch_size = 50       # Number of sequences in a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_end: 86\n",
      "val_end: 115\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "dataset = dpp.data.load_dataset(dataset_name)\n",
    "d_train, d_val, d_test = dataset.train_val_test_split(seed=seed)\n",
    "\n",
    "dl_train = d_train.get_dataloader(batch_size=batch_size, shuffle=True)\n",
    "dl_val = d_val.get_dataloader(batch_size=batch_size, shuffle=False)\n",
    "dl_test = d_test.get_dataloader(batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "print('Building model...')\n",
    "mean_log_inter_time, std_log_inter_time = d_train.get_inter_time_statistics()\n",
    "\n",
    "model = dpp.models.LogNormMixNet(\n",
    "    use_src_marks=use_src_marks,\n",
    "    use_dst_marks=use_dst_marks,\n",
    "    num_src_marks=d_train.num_src_marks,\n",
    "    num_dst_marks=d_train.num_dst_marks,\n",
    "    num_meta_classes=num_meta_classes,\n",
    "    meta_type=meta_type,\n",
    "    mean_log_inter_time=mean_log_inter_time,\n",
    "    std_log_inter_time=std_log_inter_time,\n",
    "    context_size=context_size,\n",
    "    src_mark_embedding_size=src_mark_embedding_size,\n",
    "    dst_mark_embedding_size=dst_mark_embedding_size,\n",
    "    shared_mark_embedding = shared_mark_embedding,\n",
    "    rnn_type=rnn_type,\n",
    "    num_mix_components=num_mix_components,\n",
    "    meta_embedding_size=meta_embedding_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load saved model \n",
    "model.load_state_dict(torch.load('./models/enron-event-predict-model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/datasets/work/d61-decaas/work/moo331/miniconda3/envs/IFLeurosp/lib/python3.8/site-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 tensor(1532.3123)\n",
      "2000 tensor(3345.5059)\n",
      "3000 tensor(5398.7563)\n",
      "4000 tensor(7416.7583)\n",
      "5000 tensor(9253.)\n",
      "6000 tensor(12681.4941)\n",
      "7000 tensor(13927.3926)\n"
     ]
    }
   ],
   "source": [
    "# data is in hours. 86 weeks is 14448 hours\n",
    "sampled_batch, t_end = model.sample(0, t_end=14448, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = pd.DataFrame(list(zip(sampled_batch['inter_times'][0].detach().cpu().numpy(), \n",
    "                                  sampled_batch['src_marks'][0].detach().cpu().numpy(),\n",
    "                                  sampled_batch['dst_marks'][0].detach().cpu().numpy(),\n",
    "                                  sampled_batch['meta'][0].detach().cpu().numpy())), \n",
    "               columns =['deltas', 'from', 'to', 'meta']) \n",
    "generated['ts'] = generated['deltas'].cumsum() \n",
    "generated.to_csv('Enron_generated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deltas</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>meta</th>\n",
       "      <th>ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.757284</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.757284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.093819</td>\n",
       "      <td>11.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.851103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.436657</td>\n",
       "      <td>3.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.287760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.159144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.446904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.658236</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.105140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     deltas  from     to  meta        ts\n",
       "0  0.757284  13.0    2.0     0  0.757284\n",
       "1  0.093819  11.0  124.0     0  0.851103\n",
       "2  0.436657   3.0  104.0     0  1.287760\n",
       "3  0.159144   0.0    3.0     0  1.446904\n",
       "4  0.658236  40.0    6.0     0  2.105140"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
